{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 14309,
     "status": "ok",
     "timestamp": 1756143825645,
     "user": {
      "displayName": "Nayna Sagar Dahatonde",
      "userId": "08351810259517213934"
     },
     "user_tz": -330
    },
    "id": "4ji2KPhXTw1L",
    "outputId": "6bb407fb-1da8-4bbb-8e03-7d357e42f0ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\visha\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\layers\\core\\dense.py:92: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7333 - loss: 0.7553\n",
      "Epoch 2/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7250 - loss: 0.6935 \n",
      "Epoch 3/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7167 - loss: 0.6385 \n",
      "Epoch 4/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7250 - loss: 0.5893 \n",
      "Epoch 5/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7333 - loss: 0.5479 \n",
      "Epoch 6/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7583 - loss: 0.5122 \n",
      "Epoch 7/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7833 - loss: 0.4825 \n",
      "Epoch 8/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8167 - loss: 0.4541 \n",
      "Epoch 9/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8250 - loss: 0.4279 \n",
      "Epoch 10/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8250 - loss: 0.4053 \n",
      "Epoch 11/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8583 - loss: 0.3821 \n",
      "Epoch 12/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8500 - loss: 0.3635 \n",
      "Epoch 13/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8583 - loss: 0.3451 \n",
      "Epoch 14/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8583 - loss: 0.3296 \n",
      "Epoch 15/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8750 - loss: 0.3140 \n",
      "Epoch 16/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8833 - loss: 0.3000 \n",
      "Epoch 17/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9000 - loss: 0.2897 \n",
      "Epoch 18/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9000 - loss: 0.2772 \n",
      "Epoch 19/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9250 - loss: 0.2662 \n",
      "Epoch 20/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9250 - loss: 0.2577 \n",
      "Epoch 21/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9417 - loss: 0.2486 \n",
      "Epoch 22/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9500 - loss: 0.2398 \n",
      "Epoch 23/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9500 - loss: 0.2311 \n",
      "Epoch 24/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9417 - loss: 0.2244 \n",
      "Epoch 25/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9417 - loss: 0.2168 \n",
      "Epoch 26/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9417 - loss: 0.2099 \n",
      "Epoch 27/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9417 - loss: 0.2037 \n",
      "Epoch 28/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9417 - loss: 0.1977 \n",
      "Epoch 29/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9417 - loss: 0.1907 \n",
      "Epoch 30/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9417 - loss: 0.1856 \n",
      "Epoch 31/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9417 - loss: 0.1795 \n",
      "Epoch 32/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9500 - loss: 0.1766 \n",
      "Epoch 33/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9500 - loss: 0.1704 \n",
      "Epoch 34/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9500 - loss: 0.1650 \n",
      "Epoch 35/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9500 - loss: 0.1609 \n",
      "Epoch 36/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9500 - loss: 0.1562 \n",
      "Epoch 37/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9500 - loss: 0.1530 \n",
      "Epoch 38/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9500 - loss: 0.1475 \n",
      "Epoch 39/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9500 - loss: 0.1435 \n",
      "Epoch 40/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9583 - loss: 0.1419 \n",
      "Epoch 41/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9500 - loss: 0.1361 \n",
      "Epoch 42/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9500 - loss: 0.1327 \n",
      "Epoch 43/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9583 - loss: 0.1292 \n",
      "Epoch 44/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9500 - loss: 0.1258 \n",
      "Epoch 45/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9583 - loss: 0.1224 \n",
      "Epoch 46/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9500 - loss: 0.1191 \n",
      "Epoch 47/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9667 - loss: 0.1152 \n",
      "Epoch 48/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9583 - loss: 0.1126 \n",
      "Epoch 49/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9583 - loss: 0.1092 \n",
      "Epoch 50/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9583 - loss: 0.1068 \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - accuracy: 1.0000 - loss: 0.0791\n",
      "Test Accuracy: 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\visha\\AppData\\Roaming\\Python\\Python312\\site-packages\\visualkeras\\layered.py:86: UserWarning: The legend_text_spacing_offset parameter is deprecated and will be removed in a future release.\n",
      "  warnings.warn(\"The legend_text_spacing_offset parameter is deprecated and will be removed in a future release.\")\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import libraries\n",
    "#%pip install visualkeras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import visualkeras\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1. Load Dataset\n",
    "iris = load_iris()\n",
    "X = iris.data   # Features (sepal length, sepal width, petal length, petal width)\n",
    "y = iris.target # Labels (0 = Setosa, 1 = Versicolor, 2 = Virginica)\n",
    "\n",
    "# 2. Preprocessing\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)   # Normalize features\n",
    "\n",
    "y = to_categorical(y)   # One-hot encode labels\n",
    "\n",
    "# Split dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 3. Build Neural Network Model\n",
    "model = Sequential()\n",
    "model.add(Dense(8, input_dim=4, activation='relu'))   # Hidden Layer 1\n",
    "model.add(Dense(6, activation='relu'))                # Hidden Layer 2\n",
    "model.add(Dense(3, activation='softmax'))             # Output Layer (3 classes)\n",
    "\n",
    "# 4. Compile Model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# 5. Train Model\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=5, verbose=1)\n",
    "\n",
    "# 6. Evaluate Model\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Accuracy: {accuracy*100:.2f}%\")\n",
    "\n",
    "# 7. Visualize Neural Network\n",
    "# Generate the network image\n",
    "img = visualkeras.layered_view(model, legend=True)\n",
    "\n",
    "# Show it with matplotlib\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.imshow(img)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOE6gQ4SOxJMfvJ4Ct2y61B",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
