{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "22cf9fa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequent Itemsets:\n",
      "   support         itemsets\n",
      "0      0.8          (Bread)\n",
      "1      0.8         (Butter)\n",
      "2      0.6           (Milk)\n",
      "3      0.6  (Bread, Butter)\n",
      "\n",
      "Association Rules:\n",
      "   support  confidence    lift\n",
      "0      0.6        0.75  0.9375\n",
      "1      0.6        0.75  0.9375\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "from mlxtend.frequent_patterns import apriori, association_rules\n",
    "\n",
    "# Sample transaction data\n",
    "transactions = [\n",
    "    ['Milk', 'Bread', 'Butter'],\n",
    "    ['Bread', 'Butter'],\n",
    "    ['Milk', 'Bread'],\n",
    "    ['Milk', 'Butter'],\n",
    "    ['Bread', 'Butter']\n",
    "]\n",
    "\n",
    "# Step 1: Convert transaction data into a one-hot encoded DataFrame\n",
    "te = TransactionEncoder()\n",
    "te_array = te.fit(transactions).transform(transactions)\n",
    "df = pd.DataFrame(te_array, columns=te.columns_)\n",
    "\n",
    "# Step 2: Find frequent itemsets with minimum support = 0.6\n",
    "frequent_itemsets = apriori(df, min_support=0.6, use_colnames=True)\n",
    "print(\"Frequent Itemsets:\")\n",
    "print(frequent_itemsets)\n",
    "\n",
    "# Step 3: Generate association rules with minimum confidence = 0.7\n",
    "rules = association_rules(frequent_itemsets, metric=\"confidence\", min_threshold=0.7)\n",
    "print(\"\\nAssociation Rules:\")\n",
    "print(rules[['support', 'confidence', 'lift']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2faa1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total rules generated: 44\n",
      "\n",
      "Top 10 Association Rules:\n",
      "frankfurter => other vegetables | Support: 0.005, Confidence: 0.136, Lift: 1.116\n",
      "other vegetables => frankfurter | Support: 0.005, Confidence: 0.042, Lift: 1.116\n",
      "sausage => yogurt | Support: 0.006, Confidence: 0.095, Lift: 1.109\n",
      "yogurt => sausage | Support: 0.006, Confidence: 0.067, Lift: 1.109\n",
      "soda => sausage | Support: 0.006, Confidence: 0.061, Lift: 1.015\n",
      "sausage => soda | Support: 0.006, Confidence: 0.099, Lift: 1.015\n",
      "bottled beer => whole milk | Support: 0.007, Confidence: 0.158, Lift: 0.999\n",
      "whole milk => bottled beer | Support: 0.007, Confidence: 0.045, Lift: 0.999\n",
      "sausage => whole milk | Support: 0.009, Confidence: 0.148, Lift: 0.940\n",
      "whole milk => sausage | Support: 0.009, Confidence: 0.057, Lift: 0.940\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from mlxtend.frequent_patterns import apriori, association_rules\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('Groceries_dataset.csv')\n",
    "\n",
    "# Combine Member_number and Date to define unique transactions\n",
    "df['Transaction'] = df['Member_number'].astype(str) + \"_\" + df['Date']\n",
    "\n",
    "# Create a list of item lists for each transaction\n",
    "transactions = df.groupby('Transaction')['itemDescription'].apply(list).tolist()\n",
    "\n",
    "# Encode transactions into a one-hot DataFrame\n",
    "te = TransactionEncoder()\n",
    "te_ary = te.fit(transactions).transform(transactions)\n",
    "df_encoded = pd.DataFrame(te_ary, columns=te.columns_)\n",
    "\n",
    "# Generate frequent itemsets (lower min_support if needed)\n",
    "frequent_itemsets = apriori(df_encoded, min_support=0.005, use_colnames=True)\n",
    "\n",
    "# Generate association rules (confidence threshold lowered to ensure results)\n",
    "rules = association_rules(frequent_itemsets, metric=\"lift\", min_threshold=0.8)\n",
    "\n",
    "# Select only relevant columns\n",
    "rules = rules[['antecedents', 'consequents', 'support', 'confidence', 'lift']]\n",
    "\n",
    "# Sort rules by lift descending\n",
    "rules = rules.sort_values(by='lift', ascending=False)\n",
    "\n",
    "# Convert frozensets to readable strings\n",
    "rules['antecedents'] = rules['antecedents'].apply(lambda x: ', '.join(list(x)))\n",
    "rules['consequents'] = rules['consequents'].apply(lambda x: ', '.join(list(x)))\n",
    "\n",
    "# Show count of rules found\n",
    "print(f\"\\nTotal rules generated: {len(rules)}\")\n",
    "\n",
    "# Print top 10 rules if available\n",
    "if not rules.empty:\n",
    "    print(\"\\nTop 10 Association Rules:\")\n",
    "    for i, row in rules.head(10).iterrows():\n",
    "        print(f\"{row['antecedents']} => {row['consequents']} | \"\n",
    "              f\"Support: {row['support']:.3f}, Confidence: {row['confidence']:.3f}, Lift: {row['lift']:.3f}\")\n",
    "else:\n",
    "    print(\"\\n No rules found. Try lowering min_support further (e.g., 0.003).\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
